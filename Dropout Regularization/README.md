What is dropout regularization in neural network?
  Dropout is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data. 
  It is a very efficient way of performing model averaging with neural networks. 
  The term "dropout" refers to dropping out units (both hidden and visible) in a neural network.
  
Libraries used: Numpy, Pandas, matplotlib, tensorflow, Keras, sklearn_metrics
Dataset: http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)
